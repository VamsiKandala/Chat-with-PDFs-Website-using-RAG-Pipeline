# Chat with PDF and Website using RAG Pipeline

This project implements two Retrieval-Augmented Generation (RAG) pipelines for interacting with semi-structured data. The first task focuses on PDFs, while the second task handles websites. The system extracts, chunks, embeds, and stores data for efficient retrieval. It answers user queries, performs comparisons, and generates context-rich responses using a selected Large Language Model (LLM).

# Tasks Overview

# Task 1: Chat with PDF Using RAG Pipeline

**Objective:** Implement a RAG pipeline for interacting with semi-structured data extracted from multiple PDF files. The system extracts information, chunks it for better granularity, embeds it, and stores it for efficient retrieval. Users can query the system and receive detailed responses generated by an LLM.

**Functional Requirements:**
  **1. Data Ingestion:**
     
    --> Extract text and structured data from PDF files.
    --> Segment the data into logical chunks for granularity.
    --> Convert chunks into vector embeddings using a pre-trained embedding model.
    --> Store embeddings in a vector database (e.g., FAISS) for efficient similarity-based retrieval.
    
  **2. Query Handling:**
     
    --> Convert user queries into vector embeddings.
    --> Perform a similarity search in the vector database to retrieve the most relevant chunks.
    --> Pass the retrieved chunks to the LLM to generate a response.
  
  **3. Comparison Queries:**

    --> Identify and extract relevant terms or fields to compare across multiple PDFs.
    --> Retrieve relevant chunks and process them to generate a structured comparison response (e.g., tabular or bullet-point format).

  **4. Response Generation:**
  
    --> Use the LLM with retrieval-augmented prompts to generate accurate responses.
    --> Ensure factuality by incorporating the retrieved data into the response.
    
  **Example Data:**
  
    --> From the provided PDF file, extract unemployment information from page 2 based on the degree type input.
    --> From page 6, extract the tabular data.


# Task 2: Chat with Website Using RAG Pipeline

**Objective:** Implement a RAG pipeline for interacting with structured and unstructured data extracted from websites. The system crawls and scrapes website content, converts it into embeddings, and stores it in a vector database. Users can query the system and receive accurate, context-rich responses generated by an LLM.

**Functional Requirements:**
  
  **1.Data Ingestion:**

    --> Crawl and scrape content from target websites (URLs provided).
    --> Extract key data fields, metadata, and textual content.
    --> Segment the content into chunks for better granularity.
    --> Convert chunks into vector embeddings using a pre-trained embedding model.
    --> Store embeddings in a vector database (e.g., FAISS) for efficient retrieval.

  **2. Query Handling:**

    --> Convert user queries into vector embeddings.
    --> Perform a similarity search in the vector database to retrieve the most relevant chunks.
    --> Pass the retrieved chunks to the LLM to generate a response.

  **3. Response Generation:**

    --> Use the LLM with retrieval-augmented prompts to produce responses based on retrieved data.
    --> Ensure factuality by incorporating the retrieved data directly into the response.

**Example Website Links:**
  --> https://www.uchicago.edu/
  --> https://www.washington.edu/
  --> https://www.stanford.edu/
  --> https://und.edu/

# Project Structure
##
```
/Chat-with-PDFs-Website-using-RAG-Pipeline
│
├── task1/
│   ├── app.py          # Main application for Task 1 (Chat with PDF)
│   └── pipeline.py     # RAG pipeline for Task 1 (PDF handling)
│
├── task2/
│   ├── app.py          # Main application for Task 2 (Chat with Website)
│   └── pipeline.py     # RAG pipeline for Task 2 (Website handling)
│
├── requirements.txt    # Project dependencies
└── README.md           # Project documentation
```
# Task 1: Chat with PDF (app.py & pipeline.py)
 
 **app.py:** The main application that interfaces with the user to input PDF URLs, view extracted data, and query the system for information from the PDF.
 ##
 **pipeline.py:** Contains the backend logic for extracting data from PDFs, chunking it, converting it into embeddings, and storing/retrieving data from the vector database.

# Task 2: Chat with Website (app.py & pipeline.py)
 **app.py:** Provides a user interface for interacting with websites, allowing users to input URLs, view the scraped data, and ask questions.
 ##
 **pipeline.py:** Handles the crawling, scraping, chunking, and embedding of website data. It stores this data in a vector database and retrieves the relevant chunks to generate responses.

# Requirements

 To run the project, you need to install the required dependencies. Use the following command to install the necessary packages:
 ##
-->  pip install -r requirements.txt

# Setup Instructions

**1. Clone the repository:**
  git clone https://github.com/VamsiKandala/Chat-with-PDFs-Website-using-RAG-Pipeline
  cd Chat-with-PDFs-Website-using-RAG-Pipeline
  
**2. Install the required dependencies:**
   pip install -r requirements.txt

**3. Start the Streamlit application for Task 1 (Chat with PDF):**
   streamlit run task1/app.py

**4. Start the Streamlit application for Task 2 (Chat with Website):**
   streamlit run task2/app.py

# How it Works

**Task 1 (Chat with PDF):**

   --> The user uploads a PDF or provides a URL for the PDF.
   ##
   --> The system extracts the relevant content, converts it into chunks, and generates embeddings.
   ##
   --> The user can ask questions about the PDF, and the system retrieves the relevant chunks and generates a response using an LLM.

**Task 2 (Chat with Website):**

   --> The user inputs a URL for a website to crawl and scrape.
   ##
   --> The system extracts the website’s content, generates embeddings, and stores them in a vector database.
   ##
   --> Users can query the system for specific information, and the system generates responses based on the data retrieved from the website.
